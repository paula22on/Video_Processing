{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Super Resolution"
      ],
      "metadata": {
        "id": "VqQA055eXE7k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Packages"
      ],
      "metadata": {
        "id": "wG1P6fEJXJR_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZGJiboqW-J4",
        "outputId": "d91f896c-874b-4075-9b71-02e2e8e4ae1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.7.15 (default, Oct 12 2022, 19:14:55) \n",
            "[GCC 7.5.0]\n",
            "Keras: 2.9.0\n",
            "OpenCV: 4.6.0\n",
            "NumPy: 1.21.6\n",
            "Matplotlib: 3.2.2\n",
            "Scikit-Image: 0.18.3\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import keras\n",
        "import cv2\n",
        "import numpy\n",
        "import matplotlib\n",
        "import skimage\n",
        "\n",
        "print('Python: {}'.format(sys.version))\n",
        "print('Keras: {}'.format(keras.__version__))\n",
        "print('OpenCV: {}'.format(cv2.__version__))\n",
        "print('NumPy: {}'.format(numpy.__version__))\n",
        "print('Matplotlib: {}'.format(matplotlib.__version__))\n",
        "print('Scikit-Image: {}'.format(skimage.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.optimizers import Adam\n",
        "from skimage import measure # s = measure.compare_ssim(imageA, imageB)\n",
        "#from skimage.measure import compare_ssim as ssim\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "import os"
      ],
      "metadata": {
        "id": "O2T2YLH4XMlO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "LPvzVq-OXsQZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unzip file\n",
        "import zipfile\n",
        "path_to_zip_file = '/content/video_frames.zip'\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ],
      "metadata": {
        "id": "PqVR1W2rZBsL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gIgLV029ZSDU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image quality metrics"
      ],
      "metadata": {
        "id": "w-xJh-g1YSXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function for peak signal-to-noise ratio (PSNR)\n",
        "def psnr(target, ref):\n",
        "         \n",
        "    # assume RGB image\n",
        "    target_data = target.astype(float)\n",
        "    ref_data = ref.astype(float)\n",
        "    print(target_data.shape)\n",
        "    print(ref_data.shape)\n",
        "    diff = ref_data - target_data\n",
        "    \n",
        "    diff = diff.flatten('C')\n",
        "    \n",
        "    rmse = math.sqrt(np.mean(diff ** 2.))\n",
        "\n",
        "    return 20 * math.log10(255. / rmse)"
      ],
      "metadata": {
        "id": "r75OaELVYRWq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for mean squared error (MSE)\n",
        "def mse(target, ref):\n",
        "    # the MSE between the two images is the sum of the squared difference between the two images\n",
        "    err = np.sum((target.astype('float') - ref.astype('float')) ** 2)\n",
        "    err /= float(target.shape[0] * target.shape[1])\n",
        "    \n",
        "    return err\n",
        "  "
      ],
      "metadata": {
        "id": "pyL2ubnoYZC9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function that combines all three image quality metrics\n",
        "def compare_images(target, ref):\n",
        "    scores = []\n",
        "    scores.append(psnr(target, ref))\n",
        "    scores.append(mse(target, ref))\n",
        "    scores.append(ssim(target, ref, multichannel =True))\n",
        "    \n",
        "    return scores"
      ],
      "metadata": {
        "id": "xXi0bqSTYdAd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the SRCNN Model"
      ],
      "metadata": {
        "id": "ht8JaltOYhvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def model():\n",
        "    \n",
        "    # define model type\n",
        "    SRCNN = Sequential()\n",
        "    \n",
        "    # add model layers\n",
        "    SRCNN.add(Conv2D(filters=128, kernel_size = (9, 9), kernel_initializer='glorot_uniform',\n",
        "                     activation='relu', padding='valid', use_bias=True, input_shape=(None, None, 1)))\n",
        "    SRCNN.add(Conv2D(filters=64, kernel_size = (3, 3), kernel_initializer='glorot_uniform',\n",
        "                     activation='relu', padding='same', use_bias=True))\n",
        "    SRCNN.add(Conv2D(filters=1, kernel_size = (5, 5), kernel_initializer='glorot_uniform',\n",
        "                     activation='linear', padding='valid', use_bias=True))\n",
        "    \n",
        "    # define optimizer\n",
        "    adam = Adam(lr=0.0003)\n",
        "    \n",
        "    # compile model\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    \n",
        "    return SRCNN"
      ],
      "metadata": {
        "id": "c50jWBzoYgr3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deploying the SRCNN"
      ],
      "metadata": {
        "id": "srGR5B0vY2r2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Image processing functions\n",
        "def modcrop(img, scale):\n",
        "    tmpsz = img.shape\n",
        "    sz = tmpsz[0:2]\n",
        "    sz = sz - np.mod(sz, scale)\n",
        "    img = img[0:sz[0], 1:sz[1]]\n",
        "    return img\n",
        "\n",
        "\n",
        "def shave(image, border):\n",
        "    img = image[border: -border, border: -border]\n",
        "    return img"
      ],
      "metadata": {
        "id": "05qRSVThYnSM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define main prediction function"
      ],
      "metadata": {
        "id": "ShVcVb5zZiFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(image_path, frame):\n",
        "    \n",
        "    # load the srcnn model with weights\n",
        "    srcnn = model()\n",
        "    srcnn.load_weights('/content/3051crop_weight_200.h5')\n",
        "    \n",
        "    # load the degraded and reference images\n",
        "    degraded = cv2.imread(image_path)\n",
        "    \n",
        "    # preprocess the image with modcrop\n",
        "    degraded = modcrop(degraded, 3)\n",
        "    \n",
        "    # convert the image to YCrCb - (srcnn trained on Y channel)\n",
        "    temp = cv2.cvtColor(degraded, cv2.COLOR_BGR2YCrCb)\n",
        "    \n",
        "    # create image slice and normalize  \n",
        "    Y = numpy.zeros((1, temp.shape[0], temp.shape[1], 1), dtype=float)\n",
        "    Y[0, :, :, 0] = temp[:, :, 0].astype(float) / 255\n",
        "    \n",
        "    # perform super-resolution with srcnn\n",
        "    pre = srcnn.predict(Y, batch_size=1)\n",
        "    \n",
        "    # post-process output\n",
        "    pre *= 255\n",
        "    pre[pre[:] > 255] = 255\n",
        "    pre[pre[:] < 0] = 0\n",
        "    pre = pre.astype(np.uint8)\n",
        "    \n",
        "    # copy Y channel back to image and convert to BGR\n",
        "    temp = shave(temp, 6)\n",
        "    temp[:, :, 0] = pre[0, :, :, 0]\n",
        "    output = cv2.cvtColor(temp, cv2.COLOR_YCrCb2BGR)\n",
        "\n",
        "    #save image\n",
        "    cv2.imwrite('/content/Super_resolution_videos/'+ frame, output)\n",
        "\n",
        "    \n",
        "    # remove border from reference and degraged image\n",
        "    degraded = shave(degraded.astype(np.uint8), 6)\n",
        "    \n",
        "    \n",
        "    # return images and scores\n",
        "    return output\n",
        "\n",
        "#output = predict('/content/video_frames/Frame0.jpg')"
      ],
      "metadata": {
        "id": "x56ii339Zj5B"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "import glob, os\n",
        "os.chdir(\"/content/video_frames\")\n",
        "\n",
        "frames = []\n",
        "for frame in glob.glob(\"*.jpg\"):\n",
        "    frames.append(frame)\n"
      ],
      "metadata": {
        "id": "WqHWEyA8awjF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = []\n",
        "for frame in frames:\n",
        "  frame_path = \"/content/video_frames/\" + frame\n",
        "  print(frame_path)\n",
        "  output = predict(frame_path, frame)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_F6da8NblWj",
        "outputId": "b7066008-b278-4667-d0f2-3717cbd1d93e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/video_frames/Frame41.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2799873b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame58.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame40.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame10.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame107.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame84.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame22.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame3.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame78.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame87.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame29.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame56.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame67.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame16.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame42.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame79.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame21.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame83.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame0.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame106.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame26.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame27.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame64.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame68.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame31.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame9.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame18.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame98.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame73.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame59.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame46.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame71.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame54.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame110.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame4.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame90.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame88.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame72.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame39.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame91.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame113.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame34.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame69.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame76.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame108.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame28.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame55.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame36.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame96.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame12.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame1.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame14.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame38.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame97.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame77.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame11.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame7.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame89.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame65.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame104.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame86.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame48.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame47.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame6.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame75.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame66.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame25.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame13.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame53.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame99.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame111.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame103.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame101.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame5.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame112.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame85.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame62.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame24.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame61.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame30.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame37.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame82.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame33.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame95.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame52.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame35.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame15.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame8.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame43.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame32.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame2.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame74.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame60.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame92.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame17.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame50.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame20.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame109.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame93.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame51.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame49.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame57.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame45.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame80.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame102.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame81.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame105.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame94.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame44.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame23.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame100.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame19.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame70.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/content/video_frames/Frame63.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get filename to have the frames ordered before converting to video\n",
        "name = '/content/Super_resolution_videos/'\n",
        "\n",
        "filenames = []\n",
        "for i in range(114):\n",
        "  filenames.append('/content/Super_resolution_videos/Frame' + str(i) + '.jpg')\n",
        "\n"
      ],
      "metadata": {
        "id": "Fu3dOmnzhVnM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert frames to video\n",
        "import cv2\n",
        "\n",
        "img_array = []\n",
        "for filename in filenames:\n",
        "  img = cv2.imread(filename)\n",
        "  height, width, layers = img.shape\n",
        "  size = (width, height)\n",
        "  img_array.append(img)\n",
        "\n",
        "out = cv2.VideoWriter('/content/superresolution_video.mp4', cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
        "\n",
        "for i in range(len(img_array)):\n",
        "  out.write(img_array[i])\n",
        "out.release()\n"
      ],
      "metadata": {
        "id": "6wA1TQeibqJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bSMXNDd_g6jj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}